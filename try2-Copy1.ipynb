{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fda2376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/zp/nwfjg8bs1z1_q3pzwzzd72q40000gn/T/ipykernel_712/572723695.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples are collected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "def generate_dataset():\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "                                          # scaling factor = 1.3\n",
    "                                         # minimum neighbor = 5\n",
    "        \n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)              #opening the camera\n",
    "    id =1                                  #id of first authorised person\n",
    "    img_id = 0                             # no. of image of each authorised person \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            file_name_path = \"data/Soumya.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Cropped face\", face)\n",
    "            \n",
    "        if cv2.waitKey(1)==13 or int(img_id)==2: #13 is the ASCII character of Enter\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Samples are collected\")\n",
    "generate_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab510542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/zp/nwfjg8bs1z1_q3pzwzzd72q40000gn/T/ipykernel_1342/615637736.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples are collected\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset():\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "                                          # scaling factor = 1.3\n",
    "                                         # minimum neighbor = 5\n",
    "        \n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)              #opening the camera\n",
    "    id =2                                 #id of first authorised person\n",
    "    img_id = 0                             # no. of image of each authorised person \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            file_name_path = \"data/Nayana.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Cropped face\", face)\n",
    "            \n",
    "        if cv2.waitKey(1)==13 or int(img_id)==200: #13 is the ASCII character of Enter\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Samples are collected\")\n",
    "generate_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec0d6d",
   "metadata": {},
   "source": [
    "## Create label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d074348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d9c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label(image_name):\n",
    "    name = image_name.split('.')[-3] \n",
    "    if name==\"Soumya\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name==\"Nayana\":\n",
    "        return np.array([0,1,0])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21fceb9",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d37ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb7891e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data():\n",
    "    data = []\n",
    "    for img in tqdm(os.listdir(\"data\")):\n",
    "        path=os.path.join(\"data\",img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50,50))\n",
    "        data.append([np.array(img_data), my_label(img)])\n",
    "    shuffle(data)  \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e7437e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▍                                  | 55/401 [00:00<00:00, 1727.65it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zp/nwfjg8bs1z1_q3pzwzzd72q40000gn/T/ipykernel_1342/884484945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/zp/nwfjg8bs1z1_q3pzwzzd72q40000gn/T/ipykernel_1342/3832869465.py\u001b[0m in \u001b[0;36mmy_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "data = my_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41915881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "                                          # scaling factor = 1.3\n",
    "                                         # minimum neighbor = 5\n",
    "        \n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)              #opening the camera\n",
    "    id =2                                 #id of first authorised person\n",
    "    img_id = 0                             # no. of image of each authorised person \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2LAB)\n",
    "            file_name_path = \"data/N.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Cropped face\", face)\n",
    "            \n",
    "        if cv2.waitKey(1)==13 or int(img_id)==3: #13 is the ASCII character of Enter\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Samples are collected\")\n",
    "generate_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc858ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/zp/nwfjg8bs1z1_q3pzwzzd72q40000gn/T/ipykernel_1402/3076590410.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples are collected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def generate_dataset():\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "                                          # scaling factor = 1.3\n",
    "                                         # minimum neighbor = 5\n",
    "        \n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)              #opening the camera\n",
    "    id =1                                  #id of first authorised person\n",
    "    img_id = 0                             # no. of image of each authorised person \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2BGRA)\n",
    "            file_name_path = \"data/Soumya_real.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Cropped face\", face)\n",
    "            \n",
    "        if cv2.waitKey(1)==13 or int(img_id)==100: #13 is the ASCII character of Enter\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Samples are collected\")\n",
    "generate_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9e8308",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"problem opening input stream\")? (1020506348.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/zp/nwfjg8bs1z1_q3pzwzzd72q40000gn/T/ipykernel_1402/1020506348.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    print \"problem opening input stream\"\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"problem opening input stream\")?\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "cpt = 0\n",
    "maxFrames = 30\n",
    "\n",
    "try:\n",
    "    targetDir = sys.argv[2]\n",
    "except:\n",
    "    targetDir = \"\" # if no argument, then use current directory\n",
    "\n",
    "try: # read input. eval if to transform video index to int\n",
    "    vidStream = cv2.VideoCapture(eval(sys.argv[1]))\n",
    "except:\n",
    "    print \"problem opening input stream\"\n",
    "    sys.exit(1)\n",
    "if not vidStream.isOpened():\n",
    "    print \"capture stream not open\"\n",
    "    sys.exit(1)\n",
    "\n",
    "# informations in case the input is a video file.\n",
    "nFrames = vidStream.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT)\n",
    "print \"frame number: %s\" %nFrames\n",
    "fps = vidStream.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "print \"FPS value: %s\" %fps\n",
    "\n",
    "# note that we could use frame number here, or \"while 1\"\n",
    "# so we could read from a live written file or capture devide.\n",
    "while cpt < maxFrames:\n",
    "    ret, frame = vidStream.read() # read frame and return code.\n",
    "    if not ret:\n",
    "        print \"end of stream\"\n",
    "        sys.exit(0)\n",
    "    cv2.imshow(\"test window\", frame) # show image in window\n",
    "    cv2.imwrite(os.path.join(targetDir, \"image_%04i.jpg\" %cpt), frame)\n",
    "    cpt += 1\n",
    "    keyPressed = cv2.waitKey(1) # time to wait between frames\n",
    "    if keyPressed != -1: # if user pressed a key, stop recording.\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b41465",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'NamedWindow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zp/nwfjg8bs1z1_q3pzwzzd72q40000gn/T/ipykernel_1402/4286609124.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"camera\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCaptureFromCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'NamedWindow'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "\n",
    "cv.NamedWindow(\"camera\", 1)\n",
    "\n",
    "capture = cv.CaptureFromCAM(0)\n",
    "num = 0\n",
    "while True:\n",
    "    img = cv.QueryFrame(capture)\n",
    "    cv.ShowImage(\"camera\", img)\n",
    "    cv.SaveImage('pic'+str(num)+'.jpg', img)\n",
    "    if cv.WaitKey(10) == 27:\n",
    "        break\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb997cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
